# Phase 31.1: Context Usage Indicators - Research

**Researched:** 2026-02-21
**Domain:** Dashboard UI metrics (observability.db queries + AgentCard component extension)
**Confidence:** HIGH

## Summary

This phase adds three metrics to existing agent cards on `/agents`: context window utilization %, cache hit rate, and 24h cost. All data already exists in `observability.db` (`llm_calls` table) -- no new data collection or schema changes needed. The implementation is a query extension + UI addition to an already-working page.

Key finding: the `input_tokens` column alone is NOT the context window usage. Anthropic's API breaks input into `input_tokens` (uncached), `cache_read_tokens`, and `cache_write_tokens`. The actual context window consumption is `input_tokens + cache_read_tokens + cache_write_tokens`. In practice, `input_tokens` alone is tiny (24-304 tokens) while `cache_read_tokens` is massive (109K-1M). The context window % must use the sum.

**Primary recommendation:** Extend `getAgentBoardData()` in `agents.ts` with three new aggregate queries against `llm_calls`, add a `MODEL_CONTEXT_LIMITS` constant map, and add a compact "Context" section to `AgentCard` with a Tailwind-only progress bar (no new dependencies).

<user_constraints>
## User Constraints (from CONTEXT.md)

### Locked Decisions
- Context window utilization % -- input_tokens from most recent session vs model's max context window
- Cache hit rate -- cache_read_tokens / (input_tokens + cache_read_tokens) over 24h
- 24h cost per agent -- sum of estimated_cost_usd over last 24 hours
- Extend existing AgentCard component with new "Context" section below current token counts
- No new page or dashboard section -- everything at-a-glance on /agents
- Consistent with existing card layout patterns
- Context window %: compact progress bar with color thresholds (green <60%, amber 60-80%, red >80%)
- Cache hit rate: percentage text with color coding (green >50%, amber 20-50%, red <20%)
- Cost: formatted as $X.XX, plain text
- 24h rolling aggregates for cache rate and cost (matches existing token/error pattern)
- Context % uses most recent session's input_tokens as "current context size"
- Per-session detail deferred to MC-04

### Claude's Discretion
- Exact progress bar height/styling within the card
- How to handle agents with zero calls in 24h (likely show dashes or "No data")
- Model max context lookup table (hardcoded constants vs config)
- Section label and spacing within the card

### Deferred Ideas (OUT OF SCOPE)
- Per-session context drill-down -- MC-04 (Agent detail page)
- Token efficiency ratio (output/input) -- not actionable enough for dashboard
- Time-series sparklines for context trends -- VIZ phase territory
</user_constraints>

## Standard Stack

### Core (already installed -- no new dependencies)
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| better-sqlite3 | ^12.6.2 | Query observability.db | Already used for all DB access |
| Tailwind CSS | ^3.4.10 | Progress bar styling | Already used for all UI |
| React (client component) | 18.3.1 | AgentCard is already "use client" | Existing pattern |
| SWR | ^2.4.0 | Auto-refresh on /agents | Already wired up (30s polling) |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| class-variance-authority | ^0.7.1 | Variant styling if needed | Already available via Badge |
| date-fns | ^3.6.0 | Time formatting | Only if needed for timestamps |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| Tailwind div progress bar | shadcn Progress component | Not installed; would need `npx shadcn@latest add progress`. Tailwind div is simpler and consistent with existing patterns (no other progress bars in codebase). |
| Hardcoded model limits | Config file on disk | Overkill -- only 2 models in use, values change rarely |

**Installation:** None needed. Zero new dependencies.

## Architecture Patterns

### Recommended Changes (files to modify)

```
src/
├── lib/
│   ├── constants.ts          # ADD: MODEL_CONTEXT_LIMITS map
│   ├── utils.ts              # ADD: formatCost(), formatPercent(), getContextColor(), getCacheColor()
│   └── queries/
│       └── agents.ts         # EXTEND: AgentBoardData type + getAgentBoardData() queries
├── components/
│   └── agents/
│       └── agent-card.tsx    # EXTEND: Add Context section with progress bar + cache + cost
└── app/
    └── api/
        └── agents/
            └── route.ts      # NO CHANGES (already returns getAgentBoardData())
```

### Pattern 1: Extend AgentBoardData Type

**What:** Add new fields to the existing `AgentBoardData` interface
**When to use:** New metrics derive from same DB, serve same page

```typescript
// In agents.ts -- extend existing interface
export interface AgentBoardData {
  // ... existing fields ...
  contextPct: number | null;     // 0-100, null if no recent session
  contextModel: string | null;   // model used in most recent session (for tooltip)
  cacheHitRate: number | null;   // 0-100, null if no calls in 24h
  cost24h: number;               // USD, 0 if no calls
}
```

### Pattern 2: Query in Same Function

**What:** Add new queries inside the existing `getAgentBoardData()` per-agent loop
**When to use:** Data comes from same DB, same agent iteration

```typescript
// Inside the AGENTS.map() loop in getAgentBoardData():

// --- Context window utilization (most recent session) ---
let contextPct: number | null = null;
let contextModel: string | null = null;
if (obsDb) {
  try {
    const row = obsDb.prepare(`
      SELECT model, input_tokens + cache_read_tokens + cache_write_tokens as total_context
      FROM llm_calls
      WHERE agent_id IN (${placeholders})
      ORDER BY created_at DESC LIMIT 1
    `).get(...agentIds) as { model: string; total_context: number } | undefined;
    if (row) {
      const limit = MODEL_CONTEXT_LIMITS[row.model] ?? 200_000;
      contextPct = Math.min(100, Math.round((row.total_context / limit) * 100));
      contextModel = row.model;
    }
  } catch { /* table may not exist */ }
}

// --- Cache hit rate (24h) ---
let cacheHitRate: number | null = null;
if (obsDb) {
  try {
    const row = obsDb.prepare(`
      SELECT sum(cache_read_tokens) as cache_read,
             sum(input_tokens + cache_read_tokens) as total_input
      FROM llm_calls
      WHERE agent_id IN (${placeholders})
        AND created_at > datetime('now', '-24 hours')
    `).get(...agentIds) as { cache_read: number; total_input: number } | undefined;
    if (row && row.total_input > 0) {
      cacheHitRate = Math.round((row.cache_read / row.total_input) * 100);
    }
  } catch { /* table may not exist */ }
}

// --- 24h cost ---
let cost24h = 0;
if (obsDb) {
  try {
    const row = obsDb.prepare(`
      SELECT sum(estimated_cost_usd) as cost
      FROM llm_calls
      WHERE agent_id IN (${placeholders})
        AND created_at > datetime('now', '-24 hours')
    `).get(...agentIds) as { cost: number } | undefined;
    if (row?.cost) cost24h = row.cost;
  } catch { /* table may not exist */ }
}
```

### Pattern 3: Tailwind-Only Progress Bar

**What:** Pure div-based progress bar using Tailwind classes
**When to use:** Single compact indicator, no interactivity needed

```tsx
// In agent-card.tsx -- Context section
<div>
  <div className="flex items-center justify-between text-xs mb-1">
    <span className="text-muted-foreground">Context</span>
    <span className={getContextColor(agent.contextPct)}>
      {agent.contextPct !== null ? `${agent.contextPct}%` : "—"}
    </span>
  </div>
  {agent.contextPct !== null && (
    <div className="h-1.5 w-full rounded-full bg-secondary">
      <div
        className={cn(
          "h-full rounded-full transition-all",
          agent.contextPct > 80 ? "bg-rose-500" :
          agent.contextPct > 60 ? "bg-amber-500" : "bg-emerald-500"
        )}
        style={{ width: `${agent.contextPct}%` }}
      />
    </div>
  )}
</div>
```

### Pattern 4: Color Utilities (Consistent with Existing Palette)

**What:** Color functions matching the existing green/amber/red system
**When to use:** The codebase already uses emerald-500/amber-500/rose-500 for status indicators

```typescript
// In utils.ts
export function getContextColor(pct: number | null): string {
  if (pct === null) return "text-muted-foreground";
  if (pct > 80) return "text-rose-400";
  if (pct > 60) return "text-amber-400";
  return "text-emerald-400";
}

export function getCacheColor(rate: number | null): string {
  if (rate === null) return "text-muted-foreground";
  if (rate < 20) return "text-rose-400";
  if (rate < 50) return "text-amber-400";
  return "text-emerald-400";
}

export function formatCost(usd: number): string {
  return `$${usd.toFixed(2)}`;
}
```

### Anti-Patterns to Avoid
- **Using `input_tokens` alone for context %:** Would show 0% for every agent. Must use `input_tokens + cache_read_tokens + cache_write_tokens` as total context consumption.
- **Adding a new API route:** Unnecessary. The existing `/api/agents` route already calls `getAgentBoardData()` -- just extend the return type.
- **Installing shadcn Progress component:** Adds complexity for a single 2-line div. Tailwind progress bar is the standard pattern in dashboards without accessibility requirements (this is single-user).
- **Using `cache_write_tokens` in cache hit rate:** Cache writes are NOT hits. The hit rate formula is `cache_read / (cache_read + input)`, which measures how much of the prompt was served from cache vs freshly tokenized.

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Progress bar component | Custom React component with props/variants | Inline Tailwind `<div>` with dynamic width | 2 divs, 3 classes. No abstraction needed for a single usage. |
| Color threshold logic | Complex conditional rendering in JSX | Utility functions in `utils.ts` | Keeps component clean, testable, reusable for MC-04 later |
| Model context limits | Dynamic API lookup | Hardcoded `MODEL_CONTEXT_LIMITS` constant | Only 2 models in use. Update when models change. |
| Cost formatting | `Intl.NumberFormat` with locale | Simple `$${n.toFixed(2)}` | Single-user, USD-only. Don't over-engineer. |

## Common Pitfalls

### Pitfall 1: input_tokens Is NOT Context Window Usage
**What goes wrong:** Using `input_tokens` alone for context % shows near-0% for all agents
**Why it happens:** Anthropic API splits input into `input_tokens` (uncached new tokens), `cache_read_tokens` (cached prompt), and `cache_write_tokens` (newly cached). The `input_tokens` field is just the uncached portion -- often 24-36 tokens.
**How to avoid:** Always use `input_tokens + cache_read_tokens + cache_write_tokens` as total context consumption
**Warning signs:** All agents showing 0-1% context utilization

**Verified data from production:**
| Metric | Typical Value | Range |
|--------|--------------|-------|
| input_tokens (uncached) | 24-304 | Very small |
| cache_read_tokens | 109K-1M | Massive -- this is the real context |
| cache_write_tokens | 1K-38K | Moderate |
| Total context | 60K-1.05M | Actual window usage |

### Pitfall 2: Wrong Context Window Limit for Sonnet
**What goes wrong:** Using 200K as Sonnet's limit when sessions actually reach 1M+
**Why it happens:** Standard Claude context is 200K, but Sonnet 4.5 has a 1M beta context window that this deployment uses
**How to avoid:** Set Sonnet 4.5 limit to 1,000,000 in `MODEL_CONTEXT_LIMITS`
**Warning signs:** Context % showing >100% for main agent's Sonnet sessions

### Pitfall 3: "Most Recent Session" Ambiguity
**What goes wrong:** Unclear what "most recent session" means -- most recent LLM call? Most recent session_key?
**Why it happens:** A session has multiple LLM calls with growing context. The LAST call in the most recent session has the highest context.
**How to avoid:** Query `ORDER BY created_at DESC LIMIT 1` to get the single most recent LLM call for that agent. This gives the "current" context state.
**Warning signs:** Context showing lower-than-expected values (picked an earlier call in the session)

### Pitfall 4: Division by Zero in Cache Hit Rate
**What goes wrong:** Agent with zero LLM calls in 24h causes divide-by-zero
**Why it happens:** `sum(input_tokens + cache_read_tokens)` returns 0 or NULL for inactive agents
**How to avoid:** Check `total_input > 0` before dividing. Return `null` for agents with no data.
**Warning signs:** NaN or Infinity in the UI

### Pitfall 5: Bob/Main Agent ID Split
**What goes wrong:** Missing data for Bob because some records use `agent_id = 'bob'` and others use `agent_id = 'main'`
**Why it happens:** Historical naming -- the existing queries already handle this with `WHERE agent_id IN ('main', 'bob')`
**How to avoid:** Follow the exact same pattern from the existing `getAgentBoardData()` -- the `agentIds` variable already handles this
**Warning signs:** Bob showing lower-than-expected metrics

## Code Examples

### MODEL_CONTEXT_LIMITS Constant

```typescript
// In constants.ts
// Context window limits per model (tokens)
// Source: https://platform.claude.com/docs/en/about-claude/models/overview
// Sonnet 4.5: 1M beta context (this deployment has access)
// Haiku 4.5: 200K context
export const MODEL_CONTEXT_LIMITS: Record<string, number> = {
  "claude-sonnet-4-5": 1_000_000,
  "claude-haiku-4-5": 200_000,
};

export const DEFAULT_CONTEXT_LIMIT = 200_000;
```

### Complete AgentCard Context Section

```tsx
{/* Context Metrics */}
<div className="space-y-2 border-t border-border pt-3">
  {/* Context Window Bar */}
  <div>
    <div className="flex items-center justify-between text-xs mb-1">
      <span className="text-muted-foreground">Context</span>
      <span className={getContextColor(agent.contextPct)}>
        {agent.contextPct !== null ? `${agent.contextPct}%` : "\u2014"}
      </span>
    </div>
    {agent.contextPct !== null && (
      <div className="h-1.5 w-full rounded-full bg-secondary">
        <div
          className={cn(
            "h-full rounded-full transition-all",
            agent.contextPct > 80 ? "bg-rose-500" :
            agent.contextPct > 60 ? "bg-amber-500" : "bg-emerald-500"
          )}
          style={{ width: `${Math.min(100, agent.contextPct)}%` }}
        />
      </div>
    )}
  </div>

  {/* Cache Hit Rate + Cost (inline) */}
  <div className="flex items-center justify-between text-xs">
    <span className="text-muted-foreground">Cache</span>
    <span className={getCacheColor(agent.cacheHitRate)}>
      {agent.cacheHitRate !== null ? `${agent.cacheHitRate}%` : "\u2014"}
    </span>
  </div>
  <div className="flex items-center justify-between text-xs">
    <span className="text-muted-foreground">24h Cost</span>
    <span className="text-foreground">{formatCost(agent.cost24h)}</span>
  </div>
</div>
```

### Cache Hit Rate Formula

```sql
-- Cache hit rate = how much of the prompt was served from cache
-- Formula: cache_read_tokens / (input_tokens + cache_read_tokens)
-- Note: cache_write_tokens excluded from denominator (writes aren't reads)
SELECT
  sum(cache_read_tokens) as cache_read,
  sum(input_tokens + cache_read_tokens) as total_input
FROM llm_calls
WHERE agent_id IN (?)
  AND created_at > datetime('now', '-24 hours')
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| 200K context for all models | 1M beta for Sonnet 4.5 | 2025 | Must use correct limit per model |
| `input_tokens` = full prompt | `input_tokens` = uncached only | Prompt caching launch | Context % formula must sum all three token fields |

## Data Profile (Verified from Production)

### Models in Use
| Model | Context Limit | Max Observed | Notes |
|-------|---------------|-------------|-------|
| claude-sonnet-4-5 | 1,000,000 | 1,046,086 | Main agent, cron jobs. 1M beta window |
| claude-haiku-4-5 | 200,000 | 298,003 | Heartbeat crons. Exceeds 200K -- may use extended context |

### 24h Cost Data (Sample)
| Agent | 24h Cost |
|-------|----------|
| main (Bob) | $6.81 |
| rangeos (Vector) | $0.59 |
| ops (Sentinel) | $0.53 |
| landos (Scout) | $0.42 |
| quill (Quill) | $0.02 |
| sage, ezra | $0.00 (no calls) |

### 24h Cache Data (Sample)
| Agent | Cache Read | Input | Hit Rate |
|-------|-----------|-------|----------|
| main | 49.2M | 18.6K | ~99.96% |
| ops | 23.6M | 6.3K | ~99.97% |
| rangeos | 22.7M | 5.7K | ~99.97% |
| landos | 19.0M | 6.1K | ~99.97% |
| quill | 7.3K | 30 | ~99.59% |

**Key insight:** Cache hit rates are uniformly very high (>99%). The amber/red thresholds may never trigger in normal operation. This is fine -- the indicator confirms healthy caching. If rates drop, it signals a problem worth investigating.

### Haiku Context Limit Note

Haiku sessions show up to 298K tokens total context, exceeding the documented 200K limit. This may indicate the deployment has extended context access for Haiku, or the API permits slightly exceeding the window with cached content. For safety, use 200K as the limit -- showing >100% will correctly flag unusually large sessions. Alternatively, bump to 300K if false alarms are unwanted.

**Recommendation (Claude's discretion):** Use 200K for Haiku. If the progress bar clips at 100%, that's informative (session is at/beyond the window). The `Math.min(100, pct)` in the width style prevents overflow, and showing "149%" as text is actually useful signal.

## Open Questions

1. **Haiku context limit ambiguity**
   - What we know: Docs say 200K, production data shows 298K
   - What's unclear: Whether this deployment has extended Haiku context, or whether cache tokens are counted differently
   - Recommendation: Use 200K as limit. Showing >100% is informative, not broken. Cap the progress bar width at 100% but show actual percentage in text.

2. **Context % calculation: user said "input_tokens" but data shows it should be all input tokens**
   - What we know: User's CONTEXT.md says "input_tokens from most recent session vs model's max context window"
   - What's unclear: Whether user meant the `input_tokens` DB column specifically, or "input tokens" generically (= all tokens sent to the model)
   - Recommendation: Use `input_tokens + cache_read_tokens + cache_write_tokens` as the total context consumption. The `input_tokens` column alone would show 0% for every agent. The user likely meant "tokens consumed from the context window" not the specific column name. If they meant the column, the metric would be meaningless.

## Sources

### Primary (HIGH confidence)
- EC2 observability.db direct inspection -- schema, sample data, aggregate queries all verified via SSH
- EC2 Mission Control codebase inspection -- all 7 files read directly from `~/clawd/mission-control/`
- [Anthropic Context Windows docs](https://platform.claude.com/docs/en/build-with-claude/context-windows) -- model limits, 1M beta for Sonnet
- [Anthropic Pricing docs](https://platform.claude.com/docs/en/about-claude/pricing) -- token counting, cache token classification
- [Anthropic Models Overview](https://platform.claude.com/docs/en/about-claude/models/overview) -- Sonnet 4.5 and Haiku 4.5 specs

### Secondary (MEDIUM confidence)
- [Anthropic token-saving updates](https://www.anthropic.com/news/token-saving-updates) -- cache_read_tokens don't count against ITPM rate limits (but DO count toward context window)

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH -- zero new dependencies, extending existing patterns
- Architecture: HIGH -- all files inspected, patterns verified, data profiled
- Pitfalls: HIGH -- verified against production data, token semantics confirmed via Anthropic docs

**Research date:** 2026-02-21
**Valid until:** 2026-03-21 (stable -- model limits change infrequently)
