---
phase: 29-infrastructure-database-foundation
plan: 02
type: execute
wave: 2
depends_on:
  - 29-01
files_modified:
  - ~/clawd/mission-control/src/lib/db-paths.ts
  - ~/clawd/mission-control/src/lib/db.ts
  - ~/clawd/mission-control/src/app/api/db-status/route.ts
  - ~/clawd/mission-control/src/app/page.tsx
  - ~/clawd/mission-control/src/components/dashboard/db-status-card.tsx
  - ~/clawd/mission-control/src/components/dashboard/system-status.tsx
  - ~/clawd/mission-control/src/app/layout.tsx
  - ~/clawd/mission-control/package.json
  - ~/.config/systemd/user/mission-control.service
autonomous: false
requirements:
  - INFRA-01
  - INFRA-02
  - INFRA-03

must_haves:
  truths:
    - "Opening http://100.72.143.9:3001 from any Tailscale device loads Mission Control"
    - "All 5 database status cards display on the landing page (coordination, observability, content, email, health)"
    - "Databases with data show green 'Connected' badge, last-modified timestamp, and row counts"
    - "Missing or empty databases show yellow 'Not Initialized' badge with explanation text"
    - "Mission Control auto-starts on boot via systemd and restarts on crash"
    - "systemd service has OOMScoreAdjust=500 so gateway survives if memory runs low"
    - "UFW allows port 3001 only from Tailscale CGNAT range (100.64.0.0/10)"
  artifacts:
    - path: "src/lib/db-paths.ts"
      provides: "Canonical database paths and display labels"
      contains: "DB_PATHS"
    - path: "src/lib/db.ts"
      provides: "Database connection factory with WAL + busy_timeout"
      exports: ["getDb", "getDbStatus"]
    - path: "src/app/api/db-status/route.ts"
      provides: "API endpoint returning status of all 5 databases"
      exports: ["GET"]
    - path: "src/app/page.tsx"
      provides: "Landing page with DB status card grid and system status"
    - path: "src/components/dashboard/db-status-card.tsx"
      provides: "Per-database status card component"
    - path: "src/components/dashboard/system-status.tsx"
      provides: "System uptime display"
    - path: "~/.config/systemd/user/mission-control.service"
      provides: "systemd user service for Mission Control"
  key_links:
    - from: "src/app/page.tsx"
      to: "/api/db-status"
      via: "SWR fetch on client"
      pattern: "useSWR.*api/db-status"
    - from: "src/app/api/db-status/route.ts"
      to: "src/lib/db.ts"
      via: "getDbStatus import"
      pattern: "import.*getDbStatus.*from.*db"
    - from: "src/lib/db.ts"
      to: "src/lib/db-paths.ts"
      via: "DB_PATHS import"
      pattern: "import.*DB_PATHS.*from.*db-paths"
    - from: "src/components/dashboard/db-status-card.tsx"
      to: "src/components/dashboard/relative-time.tsx"
      via: "RelativeTime import for last-modified"
      pattern: "import.*RelativeTime"
---

<objective>
Build the database connection layer, landing page with 5 DB status cards, and deploy Mission Control as a production systemd service accessible via Tailscale.

Purpose: Make Mission Control a live, always-on dashboard that shows real database health at a glance -- the foundation for all Phase 30-32 data views.
Output: Production-deployed Mission Control at http://100.72.143.9:3001 with DB status cards, systemd auto-start, and Tailscale-only access.
</objective>

<execution_context>
@/Users/andykaufman/.claude/get-shit-done/workflows/execute-plan.md
@/Users/andykaufman/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/29-infrastructure-database-foundation/29-RESEARCH.md
@.planning/phases/29-infrastructure-database-foundation/29-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Database connection layer and landing page</name>
  <files>
    ~/clawd/mission-control/src/lib/db-paths.ts
    ~/clawd/mission-control/src/lib/db.ts
    ~/clawd/mission-control/src/app/api/db-status/route.ts
    ~/clawd/mission-control/src/components/dashboard/db-status-card.tsx
    ~/clawd/mission-control/src/components/dashboard/system-status.tsx
    ~/clawd/mission-control/src/app/page.tsx
    ~/clawd/mission-control/src/app/layout.tsx
  </files>
  <action>
    SSH to EC2 (100.72.143.9) and work in ~/clawd/mission-control/:

    1. **Create db-paths.ts** (`src/lib/db-paths.ts`):
       Registry of all 5 database paths (verified from research). CRITICAL: Use the CORRECT paths:
       - coordination: `/home/ubuntu/clawd/coordination.db` (NOT ~/.openclaw/ or ~/clawd/agents/main/)
       - observability: `/home/ubuntu/clawd/agents/main/observability.db`
       - content: `/home/ubuntu/clawd/agents/main/content.db`
       - email: `/home/ubuntu/clawd/agents/main/email.db`
       - health: `/home/ubuntu/clawd/agents/main/health.db`

       Export: `DB_NAMES` (const array), `DbName` (type), `DB_PATHS` (Record), `DB_LABELS` (Record with display names: "Coordination", "Observability", "Content Pipeline", "Email", "Health & Environment").

    2. **Create db.ts** (`src/lib/db.ts`):
       Database connection factory with singleton pattern. See 29-RESEARCH.md "Pattern 1" for full implementation.
       - `getDb(name: DbName): Database.Database | null` -- lazily opens and caches read-only connections
       - `getDbStatus(name: DbName): DbStatus` -- returns connection status with row counts per table
       - Pre-check file existence with `fs.statSync` before opening (return null for missing/empty files)
       - Open with `{ readonly: true, fileMustExist: true }`
       - Check journal mode with `pragma('journal_mode')` -- if already WAL, great; if not, log warning but continue (don't try to set WAL in read-only mode)
       - Set `pragma('busy_timeout = 5000')` for concurrent read tolerance
       - Row counts: iterate `pragma('table_list')`, skip sqlite_ prefixed tables, `SELECT count(*) FROM "tablename"`
       - Last-modified: `fs.statSync(dbPath).mtime.toISOString()`

       Export types: `DbStatus = { name, status: "connected" | "not_initialized", path, lastModified?, rowCounts?, error? }`

    3. **Create db-status API route** (`src/app/api/db-status/route.ts`):
       - `export const dynamic = "force-dynamic"` (no caching)
       - `GET()` handler maps `DB_NAMES` through `getDbStatus`, returns `{ databases: DbStatus[] }`

    4. **Create db-status-card.tsx** (`src/components/dashboard/db-status-card.tsx`):
       "use client" component that renders a single database status card.
       - Props: `DbStatus` object
       - Uses shadcn Card (CardHeader, CardTitle, CardContent)
       - Uses shadcn Badge with variant: success (green) for "Connected", warning (yellow) for "Not Initialized"
       - Uses lucide-react icons: Database for the card icon, CheckCircle2 for connected, AlertTriangle for not initialized
       - Connected state: green badge, last-modified as RelativeTime component, table name + row count list
       - Not Initialized state: yellow badge, muted text "Database file not found at expected path"
       - Show the filesystem path in muted small text below the card title

    5. **Create system-status.tsx** (`src/components/dashboard/system-status.tsx`):
       "use client" component showing basic system status.
       - Display "System Status" header with a green dot when data is loading/loaded
       - Show service uptime if available (can be simple "Service Running" indicator for now)
       - Show total connected databases count: "N/5 databases connected"

    6. **Rewrite page.tsx** (`src/app/page.tsx`):
       Replace existing landing page with the Mission Control dashboard shell.
       - "use client" component (needs SWR)
       - Import `useSWR` from "swr" -- fetch from `/api/db-status`
       - No refreshInterval yet (that's DASH-03 in Phase 30), just fetch on mount
       - Layout: header with "Mission Control" title (no custom branding per user decision), then SystemStatus, then 5 DbStatusCards in a responsive grid (3 cols on lg, 2 on md, 1 on sm)
       - Dark mode by default (the HTML tag should have class="dark" -- check layout.tsx)
       - Utility-focused aesthetic: clean spacing, no decorative elements

    7. **Update layout.tsx** if needed:
       - Ensure `<html>` has `className="dark"` for dark-mode-by-default per user decision
       - Also ensure `suppressHydrationWarning` is on the html tag (research says it already is)
       - Keep Providers wrapper (now a clean passthrough from Plan 01)
       - Update page title/description to "Mission Control"
  </action>
  <verify>
    - `cat src/lib/db-paths.ts` shows 5 database paths with correct filesystem locations
    - `cat src/lib/db.ts` shows getDb and getDbStatus exports with WAL check + busy_timeout
    - `cat src/app/api/db-status/route.ts` shows GET handler with force-dynamic
    - `cat src/components/dashboard/db-status-card.tsx` shows Card with Badge variants
    - `cat src/app/page.tsx` shows useSWR fetching /api/db-status + grid of DbStatusCards
    - `grep -r "convex" src/ --include="*.ts" --include="*.tsx" -l` still returns nothing
  </verify>
  <done>Database connection layer opens all 5 databases read-only with WAL check and busy_timeout. API route returns status for all 5 DBs. Landing page renders a grid of 5 database status cards with connected/not-initialized states, using shadcn Card/Badge and RelativeTime for timestamps.</done>
</task>

<task type="auto">
  <name>Task 2: Production build, systemd service, Tailscale bind, UFW rule</name>
  <files>
    ~/clawd/mission-control/package.json
    ~/.config/systemd/user/mission-control.service
  </files>
  <action>
    SSH to EC2 (100.72.143.9) and deploy Mission Control to production:

    1. **Update package.json start script:**
       Change `"start"` script to: `"next start -H 0.0.0.0 -p 3001"`
       This binds to all interfaces so Tailscale can reach it directly.

    2. **Stop any running dev server:**
       - Check for running Next.js processes: `pgrep -f "next dev" || pgrep -f "next start"` and kill them
       - Free up port 3001

    3. **Run production build:**
       - `cd ~/clawd/mission-control && NODE_ENV=production npx next build`
       - This compiles the app for production. Monitor for OOM -- if it fails, try with `NODE_OPTIONS="--max-old-space-size=512"` to limit heap.
       - Verify build succeeds: `.next/` directory should have `server/` and `static/` subdirectories

    4. **Create systemd user service** at `~/.config/systemd/user/mission-control.service`:
       ```ini
       [Unit]
       Description=Mission Control Dashboard (Next.js)
       After=network-online.target openclaw-gateway.service
       Wants=network-online.target

       [Service]
       Type=simple
       WorkingDirectory=/home/ubuntu/clawd/mission-control
       ExecStart=/usr/bin/node /home/ubuntu/clawd/mission-control/node_modules/.bin/next start -H 0.0.0.0 -p 3001
       Restart=on-failure
       RestartSec=5
       OOMScoreAdjust=500
       Environment=NODE_ENV=production
       Environment=HOME=/home/ubuntu
       Environment="PATH=/home/ubuntu/.nvm/current/bin:/usr/local/bin:/usr/bin:/bin"

       [Install]
       WantedBy=default.target
       ```
       Key settings per user decision:
       - `OOMScoreAdjust=500` -- dashboard gets killed before gateway (OOMScoreAdjust=-900) and Tailscale
       - `Restart=on-failure` + `RestartSec=5` -- auto-recover from crashes
       - `After=openclaw-gateway.service` -- start after gateway is up
       - Production mode via `NODE_ENV=production`

       NOTE: Check what Node.js path is correct. Research says `/home/ubuntu/.nvm/current/bin` but verify with `which node` on EC2. Adjust ExecStart and PATH accordingly.

    5. **Enable and start the service:**
       ```bash
       systemctl --user daemon-reload
       systemctl --user enable mission-control.service
       systemctl --user start mission-control.service
       ```

    6. **Verify service is running:**
       - `systemctl --user status mission-control.service` should show "active (running)"
       - `curl -s http://127.0.0.1:3001 | head -20` should return HTML

    7. **Add UFW rule for Tailscale access:**
       - `sudo ufw allow from 100.64.0.0/10 to any port 3001 proto tcp comment "Mission Control via Tailscale"`
       - `sudo ufw status` to verify the rule is added
       - This restricts port 3001 to Tailscale CGNAT range only (no public internet access)

    8. **Verify Tailscale access:**
       - `curl -s http://100.72.143.9:3001 | head -20` should return HTML
       - The page should be accessible from any Tailscale-connected device at http://100.72.143.9:3001
  </action>
  <verify>
    - `systemctl --user status mission-control.service` shows "active (running)"
    - `systemctl --user is-enabled mission-control.service` shows "enabled"
    - `curl -s -o /dev/null -w "%{http_code}" http://100.72.143.9:3001` returns 200
    - `curl -s http://100.72.143.9:3001/api/db-status | python3 -m json.tool` returns JSON with 5 database statuses
    - `sudo ufw status | grep 3001` shows allow from 100.64.0.0/10
    - `grep OOMScoreAdjust ~/.config/systemd/user/mission-control.service` shows 500
  </verify>
  <done>Mission Control deployed as production systemd service. Auto-starts on boot, restarts on crash, OOMScoreAdjust=500. Accessible at http://100.72.143.9:3001 from Tailscale. UFW restricts port 3001 to Tailscale CGNAT range only.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Verify Mission Control loads from Tailscale</name>
  <files>N/A (visual verification)</files>
  <action>
    Human verification of deployed Mission Control dashboard.
    What was built: Mission Control dashboard deployed at http://100.72.143.9:3001 with 5 database status cards, dark mode, zinc+blue palette, production systemd service.

    Steps to verify:
    1. Open http://100.72.143.9:3001 in your browser from any Tailscale-connected device
    2. Verify the page loads with dark background (zinc palette) and "Mission Control" header
    3. Verify 5 database cards are visible in a grid layout
    4. Check that databases with data show green "Connected" badge and row counts:
       - coordination: ~119 rows across 4 tables
       - observability: ~10,590 rows across 2 tables
       - health: ~14 rows across 4 tables
    5. Check that databases without data show yellow "Not Initialized" badge:
       - content: 0-byte file
       - email: schema exists but 0 rows (may show Connected with 0 rows, or Not Initialized)
    6. Verify "System Status" section shows connected database count
    7. Verify last-modified timestamps display as relative time (e.g., "5 minutes ago")
  </action>
  <verify>User confirms the dashboard loads correctly with expected data and layout</verify>
  <done>User types "approved" or describes issues. Resume signal: "approved" or describe any issues with the layout, colors, data, or accessibility.</done>
</task>

</tasks>

<verification>
1. `systemctl --user status mission-control.service` is active and enabled
2. `curl -s http://100.72.143.9:3001` returns HTML (not connection refused)
3. `curl -s http://100.72.143.9:3001/api/db-status` returns JSON with 5 database entries
4. At least 3 databases show "connected" status (coordination, observability, health)
5. `sudo ufw status | grep 3001` shows Tailscale CGNAT rule
6. `grep -r "convex" ~/clawd/mission-control/src/ --include="*.ts" --include="*.tsx" -l` returns nothing
7. No hydration mismatch warnings in browser console
</verification>

<success_criteria>
- http://100.72.143.9:3001 loads Mission Control from any Tailscale device without SSH tunneling
- 5 database status cards display with correct connected/not-initialized states
- Databases with data show green badge, last-modified relative time, and row counts per table
- Missing databases show yellow badge with explanation
- systemd service auto-starts, restarts on crash, has OOMScoreAdjust=500
- UFW restricts port 3001 to 100.64.0.0/10 (Tailscale only)
- Dark mode active with zinc palette and blue accents
</success_criteria>

<output>
After completion, create `.planning/phases/29-infrastructure-database-foundation/29-02-SUMMARY.md`
</output>
