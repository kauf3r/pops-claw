---
phase: 18-pipeline-monitoring
plan: 02
type: execute
wave: 2
depends_on: ["18-01"]
files_modified:
  - /home/ubuntu/clawd/agents/ops/STUCK_DETECTION.md
  - /home/ubuntu/.openclaw/cron/jobs.json
autonomous: true

must_haves:
  truths:
    - "Sentinel detects stuck pipeline items daily (topics/articles not progressing)"
    - "Stuck detection alerts post to #content-pipeline channel for content agent visibility"
    - "Silent-skip when no stuck items found (no noise)"
  artifacts:
    - path: "/home/ubuntu/clawd/agents/ops/STUCK_DETECTION.md"
      provides: "Reference doc with stuck-detection SQL queries and thresholds"
    - path: "/home/ubuntu/.openclaw/cron/jobs.json"
      provides: "stuck-check cron entry"
  key_links:
    - from: "stuck-check cron"
      to: "STUCK_DETECTION.md"
      via: "Sentinel reads reference doc on cron trigger"
    - from: "STUCK_DETECTION.md SQL queries"
      to: "/home/ubuntu/clawd/content.db"
      via: "sqlite3 CLI queries in embedded mode (host paths)"
---

<objective>
Deploy daily stuck-item detection to Sentinel (ops agent) that identifies content pipeline bottlenecks: topics claimed too long without an article, articles stuck in review, approved articles not published.

Purpose: MN-02 (stuck detection) + MN-03 (Sentinel integration) — surface pipeline bottlenecks before they become invisible backlogs.
Output: STUCK_DETECTION.md reference doc on EC2 + daily cron job targeting ops.
</objective>

<execution_context>
@/Users/andykaufman/.claude/get-shit-done/workflows/execute-plan.md
@/Users/andykaufman/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create STUCK_DETECTION.md reference doc for Sentinel</name>
  <files>/home/ubuntu/clawd/agents/ops/STUCK_DETECTION.md</files>
  <action>
SSH to EC2 (100.72.143.9) and create /home/ubuntu/clawd/agents/ops/STUCK_DETECTION.md with the following sections:

**Section 1: Stuck Detection Instructions**
- Agent reads this doc when triggered by daily stuck-check cron
- Query content.db for items exceeding age thresholds
- If stuck items found: post alert to #content-pipeline (C0ADWCMU5F0) so content agents see it
- If NO stuck items found: do nothing (silent-skip pattern, no noise)

**Section 2: Stuck Topic Detection**
Thresholds:
- Topic in "researching" status for >3 days = stuck
- Topic in "writing" status (claimed but no article created) for >5 days = stuck

SQL queries using sqlite3 /home/ubuntu/clawd/content.db (HOST path, not /workspace/):
```sql
-- Stuck topics: researching > 3 days
SELECT id, title, claimed_by, claimed_at FROM topics
WHERE status = 'researching'
AND claimed_at < datetime('now', '-3 days');

-- Stuck topics: writing status > 5 days with no article
SELECT t.id, t.title, t.claimed_by, t.claimed_at FROM topics t
LEFT JOIN articles a ON a.topic_id = t.id
WHERE t.status = 'writing'
AND t.claimed_at < datetime('now', '-5 days')
AND a.id IS NULL;
```

**Section 3: Stuck Article Detection**
Thresholds:
- Article in "writing" status for >5 days = stuck
- Article in "review" status for >3 days = stuck
- Article in "revision" status for >5 days = stuck (re-review loop)
- Article in "approved" status for >7 days = not published (missed publish window)

```sql
-- Stuck articles by status with age thresholds
SELECT id, title, status, claimed_by, updated_at,
  CAST(julianday('now') - julianday(updated_at) AS INTEGER) as days_stuck
FROM articles
WHERE (status = 'writing' AND updated_at < datetime('now', '-5 days'))
   OR (status = 'review' AND updated_at < datetime('now', '-3 days'))
   OR (status = 'revision' AND updated_at < datetime('now', '-5 days'))
   OR (status = 'approved' AND updated_at < datetime('now', '-7 days'));
```

**Section 4: Stuck Social Posts**
```sql
-- Draft social posts for published articles (should have been generated)
SELECT a.title, sp.platform, sp.status, sp.created_at
FROM social_posts sp
JOIN articles a ON a.id = sp.article_id
WHERE sp.status = 'draft'
AND sp.created_at < datetime('now', '-7 days');
```

**Section 5: Alert Format**
If any stuck items found, post to #content-pipeline (C0ADWCMU5F0):
- Header: "Pipeline Stuck Item Alert"
- List each stuck item with: type (topic/article), title, status, days stuck, assigned agent
- Suggest action: "Topic X claimed by rangeos has been in 'researching' for 5 days — may need attention"
- Keep concise — just the facts + suggested action

**Section 6: Important Notes**
- This runs in EMBEDDED mode — use host paths, not /workspace/
- DB path: /home/ubuntu/clawd/content.db
- Post alerts to #content-pipeline (C0ADWCMU5F0), NOT #ops — content agents need to see these
- If NO stuck items found from any query, do NOT post anything (silent-skip)
- Use `sessions_send` to #content-pipeline channel for alerts
  </action>
  <verify>
SSH verify: `cat /home/ubuntu/clawd/agents/ops/STUCK_DETECTION.md | wc -l` returns 60+ lines.
SSH verify: `grep -c 'content.db' /home/ubuntu/clawd/agents/ops/STUCK_DETECTION.md` returns 3+ (host path references).
SSH verify: `grep 'workspace' /home/ubuntu/clawd/agents/ops/STUCK_DETECTION.md` returns 0 matches (no sandbox paths).
SSH verify: `grep 'C0ADWCMU5F0' /home/ubuntu/clawd/agents/ops/STUCK_DETECTION.md` returns 1+ match (channel ID present).
  </verify>
  <done>STUCK_DETECTION.md deployed to Sentinel's workspace with SQL queries for 4 stuck-item categories, age thresholds, silent-skip pattern, and #content-pipeline alert delivery.</done>
</task>

<task type="auto">
  <name>Task 2: Create daily stuck-check cron job for Sentinel</name>
  <files>/home/ubuntu/.openclaw/cron/jobs.json</files>
  <action>
SSH to EC2 and create a daily cron job:

```bash
/home/ubuntu/.npm-global/bin/openclaw cron add \
  --name "stuck-check" \
  --cron "0 17 * * *" \
  --message "Read /home/ubuntu/clawd/agents/ops/STUCK_DETECTION.md and check for stuck pipeline items. Query content.db at /home/ubuntu/clawd/content.db using sqlite3 CLI. If stuck items found, post alert to #content-pipeline (C0ADWCMU5F0). If nothing stuck, do nothing." \
  --timeout 120000
```

Schedule: Daily at 17:00 UTC = 9 AM PT. Runs after content agent crons (topic-research 10 AM, writing-check 11 AM, review-check 10 AM) have had time to process, but early enough to surface issues same day.

After CLI creates the job, patch jobs.json to set:
- `sessionTarget`: "ops" (CLI only supports main|isolated, must patch directly)
- `payload.kind`: "agentTurn" (must match sessionTarget=ops)
- `payload.model`: "sonnet" (needs SQL reasoning)
- Remove any `delivery` config (not needed for non-isolated sessions)

Restart gateway after patching: `systemctl --user restart openclaw-gateway.service`

Verify the job appears in cron list and has correct config.
  </action>
  <verify>
SSH verify: `/home/ubuntu/.npm-global/bin/openclaw cron list | grep stuck-check` shows the job.
SSH verify: `cat /home/ubuntu/.openclaw/cron/jobs.json | python3 -c "import sys,json; jobs=json.load(sys.stdin); sc=[j for j in jobs if j.get('name')=='stuck-check']; print(sc[0]['sessionTarget'] if sc else 'NOT FOUND')"` returns "ops".
SSH verify: `systemctl --user is-active openclaw-gateway.service` returns "active".
  </verify>
  <done>stuck-check cron job fires daily at 9 AM PT targeting Sentinel (ops), using agentTurn with sonnet model, reading STUCK_DETECTION.md for stuck-item SQL queries with silent-skip when nothing is stuck.</done>
</task>

</tasks>

<verification>
- STUCK_DETECTION.md exists on EC2 at /home/ubuntu/clawd/agents/ops/ with SQL queries for 4 stuck-item categories
- stuck-check cron job exists in jobs.json with sessionTarget=ops, kind=agentTurn, model=sonnet
- Gateway is active after restart
- No /workspace/ paths in STUCK_DETECTION.md (embedded mode compliance)
- Silent-skip pattern documented (no Slack message when nothing stuck)
- Alert target is #content-pipeline (C0ADWCMU5F0), not #ops
</verification>

<success_criteria>
Daily stuck detection cron is configured and will fire every day at 9 AM PT, targeting Sentinel with instructions to query content.db for stuck items and alert #content-pipeline only when bottlenecks are found.
</success_criteria>

<output>
After completion, create `.planning/phases/18-pipeline-monitoring/18-02-SUMMARY.md`
</output>
