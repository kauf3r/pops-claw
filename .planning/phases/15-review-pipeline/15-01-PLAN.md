---
phase: 15-review-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - "~/.openclaw/skills/content-editor/SKILL.md (EC2)"
  - "~/clawd/agents/sage/REVIEW_SESSION.md (EC2)"
autonomous: true

must_haves:
  truths:
    - "content-editor skill is discoverable by all agents via OpenClaw skill loader"
    - "Skill describes complete editorial review workflow with scoring rubric, reviewer notes, and status transitions (review->approved or review->revision)"
    - "Sage knows how to claim an article in 'review' status, score it on SEO/readability/accuracy, write reviewer_notes, and route it to 'approved' or 'revision'"
    - "REVIEW_SESSION.md reference doc guides Sage through a 2x/day review session end-to-end"
  artifacts:
    - path: "~/.openclaw/skills/content-editor/SKILL.md"
      provides: "Editorial review skill with scoring rubric (SEO 1-10, readability 1-10, accuracy 1-10), reviewer notes, article claiming, status routing"
      contains: "content-editor"
    - path: "~/clawd/agents/sage/REVIEW_SESSION.md"
      provides: "Review session reference doc with step-by-step instructions for article selection, scoring, feedback, and status routing"
      contains: "Review Session"
  key_links:
    - from: "content-editor SKILL.md"
      to: "/workspace/content.db"
      via: "UPDATE articles SET seo_score, readability_score, accuracy_score, reviewer_notes, status"
      pattern: "UPDATE articles"
    - from: "content-editor SKILL.md"
      to: "/workspace/content.db"
      via: "pipeline_activity logging for review decisions"
      pattern: "INSERT INTO pipeline_activity"
    - from: "content-editor SKILL.md"
      to: "/workspace/content.db"
      via: "Article claiming with BEGIN IMMEDIATE"
      pattern: "UPDATE articles SET claimed_by = 'sage'"
    - from: "REVIEW_SESSION.md"
      to: "content-editor SKILL.md"
      via: "References skill for editorial review workflow"
      pattern: "content-editor"
---

<objective>
Create the content-editor skill and REVIEW_SESSION.md reference doc for Sage.

Purpose: Sage needs a skill that teaches editorial review (scoring rubric for SEO/readability/accuracy on 1-10 scale, structured reviewer notes, approval/revision routing) and a reference doc that guides review sessions -- claim articles in 'review' status, score and evaluate them, route to 'approved' (score >= 7 on all dimensions) or 'revision' (with actionable feedback for Quill).
Output: content-editor SKILL.md in skills directory + REVIEW_SESSION.md in Sage's workspace.
</objective>

<execution_context>
@/Users/andykaufman/.claude/get-shit-done/workflows/execute-plan.md
@/Users/andykaufman/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-content-db-agent-setup/12-02-SUMMARY.md
@.planning/phases/14-writing-pipeline/14-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create content-editor skill</name>
  <files>~/.openclaw/skills/content-editor/SKILL.md (EC2)</files>
  <action>
Create `~/.openclaw/skills/content-editor/` directory and write SKILL.md on EC2.

The skill follows the established SKILL.md pattern (YAML frontmatter with name + description, then structured body). Model after the seo-writer skill (Phase 14-01) but for editorial review instead of writing.

**Frontmatter:**
```yaml
---
name: Content Editor
description: "Review and score articles for AirSpace Integration's UAS/drone content pipeline. Covers editorial quality assessment, SEO scoring, readability analysis, accuracy verification, and routing decisions."
---
```

**Skill body sections:**

**1. Overview**
This skill enables editorial review for the AirSpace Integration content marketing pipeline. The editor claims articles in 'review' status from content.db, evaluates them against a scoring rubric (SEO, readability, accuracy), writes structured reviewer notes, and routes articles to either 'approved' (ready for publishing) or 'revision' (back to writer with actionable feedback).

**2. Prerequisites**
- `/workspace/content.db` must be accessible (bind-mounted from host)
- `sqlite3` CLI available in sandbox
- Read PRODUCT_CONTEXT.md in your workspace for UAS domain rules before reviewing
- Browser available for fact-checking claims in articles

**3. Article Claiming Workflow**

Before reviewing, claim an article from the review queue using the claim locking protocol (CP-05):

```sql
BEGIN IMMEDIATE;

UPDATE articles
SET claimed_by = 'sage', claimed_at = CURRENT_TIMESTAMP
WHERE id = <article_id>
  AND status = 'review'
  AND (claimed_by IS NULL OR claimed_by = 'quill');

-- Verify exactly 1 row was updated (claim succeeded)
-- If 0 rows: article was already claimed by another reviewer, pick a different one

INSERT INTO pipeline_activity (entity_type, entity_id, agent_id, action, old_status, new_status, details)
VALUES ('articles', <article_id>, 'sage', 'claimed_for_review', 'review', 'review', 'Claimed for editorial review');

COMMIT;
```

NOTE: Articles in 'review' status have `claimed_by = 'quill'` from the writing phase. The WHERE clause allows claiming from quill OR NULL.

**Selection priority:**
1. Pick oldest article in review first (FIFO -- first written, first reviewed)
2. Query: `SELECT a.id, a.title, a.slug, a.word_count, a.meta_description, a.created_at, t.keywords, t.brief FROM articles a JOIN topics t ON a.topic_id = t.id WHERE a.status = 'review' ORDER BY a.created_at ASC LIMIT 5;`

**4. Scoring Rubric**

Score each article on three dimensions, each 1-10:

**SEO Score (seo_score):**
| Score | Criteria |
|-------|----------|
| 9-10 | Primary keyword in H1, first paragraph, 2+ H2s, conclusion. 3-5 secondary keywords used naturally. Meta description 150-160 chars with keyword. Keyword density 1-2%. |
| 7-8 | Primary keyword in H1 and most key positions. Secondary keywords present. Meta description exists but may be slightly off length. |
| 5-6 | Primary keyword present but inconsistently placed. Missing from some H2s or conclusion. Meta description weak or missing. |
| 3-4 | Keyword usage is sparse or unnatural. Missing from H1 or first paragraph. No meta description. |
| 1-2 | No discernible keyword strategy. |

**Readability Score (readability_score):**
| Score | Criteria |
|-------|----------|
| 9-10 | Short paragraphs (2-4 sentences). Active voice throughout. Clear H2/H3 hierarchy with 3-5 H2s. 2+ bullet/numbered lists. Smooth transitions between sections. Professional but approachable tone. |
| 7-8 | Mostly short paragraphs. Good structure. Minor passive voice or long paragraphs. At least 1 list. |
| 5-6 | Some long paragraphs (5+ sentences). Structure exists but inconsistent. Tone wavers between sections. |
| 3-4 | Dense paragraphs. Poor structure. Inconsistent tone. Hard to scan. |
| 1-2 | Wall of text. No clear structure. |

**Accuracy Score (accuracy_score):**
| Score | Criteria |
|-------|----------|
| 9-10 | All claims verifiable. Statistics have implied or stated sources. Technical terms correctly used. Aligns with PRODUCT_CONTEXT.md DO rules. No DON'T violations. |
| 7-8 | Claims are plausible and mostly verifiable. Minor technical imprecisions that don't mislead. No DON'T violations. |
| 5-6 | Some unverifiable claims. A few technical errors. Minor PRODUCT_CONTEXT.md alignment issues. |
| 3-4 | Multiple unverifiable claims. Technical errors that could mislead. PRODUCT_CONTEXT.md violations present. |
| 1-2 | Significant factual errors or fabricated statistics. |

**5. Reviewer Notes Format**

Write structured reviewer notes that go into the `reviewer_notes` column. Format:

```
## Editorial Review

**Overall Assessment:** [1-2 sentence summary]

**SEO (X/10):** [Brief justification]
**Readability (X/10):** [Brief justification]
**Accuracy (X/10):** [Brief justification]

**Decision:** [APPROVED / REVISION NEEDED]

{If revision needed:}
### Required Changes
1. [Specific, actionable change with location in article]
2. [Another specific change]
3. [...]

### Suggestions (Optional)
- [Non-blocking improvement ideas]
```

Keep reviewer_notes concise but actionable. A writer should be able to address all required changes without guessing what the editor wants.

**6. Routing Decision**

**Approve (status -> 'approved'):** All three scores >= 7. No PRODUCT_CONTEXT.md DON'T violations. All facts verifiable.

**Revision (status -> 'revision'):** Any score < 7 OR any PRODUCT_CONTEXT.md violation OR any unverifiable claims presented as fact.

When routing to 'revision', the article goes back to Quill. Include specific required changes in reviewer_notes so Quill knows exactly what to fix.

**7. Storing the Review**

After scoring and writing notes, update the article:

**For APPROVED articles:**
```sql
BEGIN IMMEDIATE;

UPDATE articles
SET seo_score = <score>,
    readability_score = <score>,
    accuracy_score = <score>,
    reviewer_notes = '<structured notes>',
    status = 'approved',
    claimed_by = 'sage',
    updated_at = CURRENT_TIMESTAMP
WHERE id = <article_id>
  AND status = 'review';

-- Log activity (CP-06)
INSERT INTO pipeline_activity (entity_type, entity_id, agent_id, action, old_status, new_status, details)
VALUES ('articles', <article_id>, 'sage', 'approved', 'review', 'approved', 'Passed editorial review (SEO:<s>/10, Read:<r>/10, Acc:<a>/10)');

COMMIT;
```

**For REVISION articles:**
```sql
BEGIN IMMEDIATE;

UPDATE articles
SET seo_score = <score>,
    readability_score = <score>,
    accuracy_score = <score>,
    reviewer_notes = '<structured notes with required changes>',
    status = 'revision',
    claimed_by = 'sage',
    updated_at = CURRENT_TIMESTAMP
WHERE id = <article_id>
  AND status = 'review';

-- Log activity (CP-06)
INSERT INTO pipeline_activity (entity_type, entity_id, agent_id, action, old_status, new_status, details)
VALUES ('articles', <article_id>, 'sage', 'revision_requested', 'review', 'revision', 'Needs revision (SEO:<s>/10, Read:<r>/10, Acc:<a>/10). See reviewer_notes for required changes.');

COMMIT;
```

**8. Handling Revisions (Re-reviews)**

Articles that come back after revision (status = 'review' again, with existing reviewer_notes) should be re-reviewed:
1. Read existing reviewer_notes to see what was requested
2. Verify each required change was addressed
3. Re-score all three dimensions
4. Append new review to reviewer_notes (keep history):

```
---
## Re-review (YYYY-MM-DD)

**Previous issues addressed:** [Yes/Partially/No for each]

**SEO (X/10):** [Updated assessment]
**Readability (X/10):** [Updated assessment]
**Accuracy (X/10):** [Updated assessment]

**Decision:** [APPROVED / REVISION NEEDED]
{Required changes if still not passing}
```

**9. Error Handling**
- If content.db is locked (SQLITE_BUSY), retry after 2 seconds, max 3 retries
- If article was already claimed (0 rows updated), pick next article from queue
- If no articles in review queue, post to #content-pipeline: "No articles awaiting review. Pipeline is clear."
- If browser is needed for fact-checking but unavailable, note in reviewer_notes which claims could not be verified
- Always validate against PRODUCT_CONTEXT.md rules during review

**10. Tips**
- Read the full article before scoring (don't score section by section)
- Check article title against the topic keywords from topics table
- Verify word count claim matches actual content length
- Be constructive in reviewer_notes -- the writer is an AI agent that needs clear, specific instructions
- For accuracy checks, verify any statistics or case study claims using browser search
- Check that H1 title is 50-70 characters and meta description is 150-160 characters
- Look for `[INTERNAL_LINK: topic]` placeholders and verify they reference real topic areas
- Cross-reference article against recent articles to catch duplicate coverage: `SELECT title, slug FROM articles WHERE status IN ('approved', 'published') ORDER BY created_at DESC LIMIT 10;`

Verify skill is detected by restarting gateway and checking skills output.
  </action>
  <verify>
SSH to EC2 and confirm:
1. `ls ~/.openclaw/skills/content-editor/SKILL.md` -- file exists
2. `head -5 ~/.openclaw/skills/content-editor/SKILL.md` -- has correct frontmatter (name: Content Editor)
3. `grep -c "UPDATE articles" ~/.openclaw/skills/content-editor/SKILL.md` -- returns at least 2 (approve + revision)
4. `grep -c "BEGIN IMMEDIATE" ~/.openclaw/skills/content-editor/SKILL.md` -- returns at least 3 (claim + approve + revision)
5. `grep -c "seo_score" ~/.openclaw/skills/content-editor/SKILL.md` -- returns at least 3
6. `grep -c "PRODUCT_CONTEXT" ~/.openclaw/skills/content-editor/SKILL.md` -- returns at least 1
7. Restart gateway: `systemctl --user restart openclaw-gateway`
8. Check gateway loaded skill: `journalctl --user -u openclaw-gateway -n 50 --no-pager | grep -i "content-editor"` or check skill count in startup logs
  </verify>
  <done>content-editor SKILL.md deployed at ~/.openclaw/skills/content-editor/SKILL.md with complete editorial review workflow, scoring rubric (SEO/readability/accuracy 1-10), reviewer notes format, approval/revision routing, and activity logging</done>
</task>

<task type="auto">
  <name>Task 2: Create REVIEW_SESSION.md reference doc in Sage's workspace</name>
  <files>~/clawd/agents/sage/REVIEW_SESSION.md (EC2)</files>
  <action>
Create a reference document at `~/clawd/agents/sage/REVIEW_SESSION.md` on EC2 that the cron-triggered agent will read and follow.

This follows the established reference doc pattern (TOPIC_RESEARCH.md for rangeos, WRITING_SESSION.md for quill).

**CRITICAL:** This runs in sandbox (Docker), NOT embedded mode. Sage's cron uses `sessionTarget: "sage"` with `kind: "agentTurn"`, which runs in Docker sandbox. Use `/workspace/` paths for content.db, NOT host paths.

**Content for REVIEW_SESSION.md:**

```markdown
# Review Session

You are Sage, the editorial reviewer for AirSpace Integration's content marketing pipeline. This document guides your review session.

## Before You Start

1. Read your PRODUCT_CONTEXT.md for UAS domain rules (DO/DON'T list)
2. Check if there are articles ready for review:

```sql
SELECT a.id, a.title, a.slug, a.word_count, a.meta_description, a.created_at, t.keywords, t.brief
FROM articles a
JOIN topics t ON a.topic_id = t.id
WHERE a.status = 'review'
ORDER BY a.created_at ASC
LIMIT 5;
```

If no articles are in review (0 rows), post to #content-pipeline: "No articles awaiting review. Pipeline is clear." and stop.

3. Check if you already have an article claimed:

```sql
SELECT a.id, a.title, a.word_count
FROM articles a
WHERE a.status = 'review' AND a.claimed_by = 'sage';
```

If you have one claimed, continue reviewing that one.

4. Check pipeline health:

```sql
SELECT status, COUNT(*) as cnt FROM articles GROUP BY status;
```

## Review Process

Use the content-editor skill for your complete review workflow. Key steps:

### Step 1: Claim an Article

If you don't have one claimed, claim the oldest article in review:

```sql
BEGIN IMMEDIATE;

UPDATE articles
SET claimed_by = 'sage', claimed_at = CURRENT_TIMESTAMP
WHERE id = <article_id>
  AND status = 'review'
  AND (claimed_by IS NULL OR claimed_by = 'quill');

INSERT INTO pipeline_activity (entity_type, entity_id, agent_id, action, old_status, new_status, details)
VALUES ('articles', <article_id>, 'sage', 'claimed_for_review', 'review', 'review', 'Claimed for editorial review');

COMMIT;
```

Database path: `/workspace/content.db`

If 0 rows updated, the article was claimed by someone else. Try the next one.

### Step 2: Read the Full Article

Retrieve the article body:

```sql
SELECT a.body, a.title, a.meta_description, a.word_count, a.slug, a.reviewer_notes,
       t.title as topic_title, t.brief, t.keywords, t.source_url
FROM articles a
JOIN topics t ON a.topic_id = t.id
WHERE a.id = <article_id>;
```

If `reviewer_notes` is not empty, this is a re-review after revision. Read previous notes to see what was requested.

### Step 3: Score the Article

Use the content-editor skill scoring rubric:

**SEO (1-10):** Check keyword placement (H1, first paragraph, H2s, conclusion), keyword density, meta description quality, secondary keywords.

**Readability (1-10):** Check paragraph length (2-4 sentences), H2/H3 structure (3-5 H2s), lists usage (2+), active voice, tone consistency.

**Accuracy (1-10):** Verify claims using browser search if needed. Check PRODUCT_CONTEXT.md compliance. Ensure no fabricated statistics.

### Step 4: Write Reviewer Notes

Follow the content-editor skill format:

```
## Editorial Review

**Overall Assessment:** [1-2 sentence summary]

**SEO (X/10):** [Brief justification]
**Readability (X/10):** [Brief justification]
**Accuracy (X/10):** [Brief justification]

**Decision:** [APPROVED / REVISION NEEDED]

{If revision needed:}
### Required Changes
1. [Specific change with location]
2. [...]
```

### Step 5: Route the Article

**If all scores >= 7 and no PRODUCT_CONTEXT.md violations:**

```sql
BEGIN IMMEDIATE;

UPDATE articles
SET seo_score = <score>,
    readability_score = <score>,
    accuracy_score = <score>,
    reviewer_notes = '<notes>',
    status = 'approved',
    claimed_by = 'sage',
    updated_at = CURRENT_TIMESTAMP
WHERE id = <article_id> AND status = 'review';

INSERT INTO pipeline_activity (entity_type, entity_id, agent_id, action, old_status, new_status, details)
VALUES ('articles', <article_id>, 'sage', 'approved', 'review', 'approved', 'Passed editorial review (SEO:<s>/10, Read:<r>/10, Acc:<a>/10)');

COMMIT;
```

**If any score < 7 or violations found:**

```sql
BEGIN IMMEDIATE;

UPDATE articles
SET seo_score = <score>,
    readability_score = <score>,
    accuracy_score = <score>,
    reviewer_notes = '<notes with required changes>',
    status = 'revision',
    claimed_by = 'sage',
    updated_at = CURRENT_TIMESTAMP
WHERE id = <article_id> AND status = 'review';

INSERT INTO pipeline_activity (entity_type, entity_id, agent_id, action, old_status, new_status, details)
VALUES ('articles', <article_id>, 'sage', 'revision_requested', 'review', 'revision', 'Needs revision (SEO:<s>/10, Read:<r>/10, Acc:<a>/10)');

COMMIT;
```

Database path: `/workspace/content.db`

### Step 6: Session Summary

Post your review summary to #content-pipeline with:
- Article title and ID
- Scores (SEO/Readability/Accuracy)
- Decision (approved or revision needed)
- If revision: summary of required changes
- Pipeline health snapshot

```sql
SELECT status, COUNT(*) as cnt FROM articles GROUP BY status;
```

## Target Output

- Review all articles in the queue (up to 3 per session)
- Each review: score, notes, and routing decision
- Quality bar: scores >= 7 on all dimensions for approval

## Error Handling

- If content.db is locked: retry after 2 seconds, max 3 retries
- If article claim fails (0 rows): try next article in queue
- If no articles in review: post to #content-pipeline and stop
- If browser unavailable for fact-checking: note which claims unverified in reviewer_notes
- Always validate against PRODUCT_CONTEXT.md during review
```

Write this file via SSH to the EC2 instance.
  </action>
  <verify>
SSH to EC2 and confirm:
1. `ls -la ~/clawd/agents/sage/REVIEW_SESSION.md` -- file exists
2. `head -3 ~/clawd/agents/sage/REVIEW_SESSION.md` -- starts with "# Review Session"
3. `grep -c "UPDATE articles" ~/clawd/agents/sage/REVIEW_SESSION.md` -- returns at least 2
4. `grep -c "/workspace/content.db" ~/clawd/agents/sage/REVIEW_SESSION.md` -- returns at least 1 (sandbox paths)
5. `grep -c "BEGIN IMMEDIATE" ~/clawd/agents/sage/REVIEW_SESSION.md` -- returns at least 3 (claim + approve + revision)
6. `grep -c "content-editor" ~/clawd/agents/sage/REVIEW_SESSION.md` -- returns at least 1 (references the skill)
7. `grep -c "seo_score" ~/clawd/agents/sage/REVIEW_SESSION.md` -- returns at least 1
  </verify>
  <done>REVIEW_SESSION.md deployed to Sage workspace with complete review session instructions, article claiming, scoring workflow, approval/revision routing, and session summary</done>
</task>

</tasks>

<verification>
After both tasks:
1. `ls ~/.openclaw/skills/content-editor/SKILL.md` -- skill file exists
2. `ls ~/clawd/agents/sage/REVIEW_SESSION.md` -- reference doc exists
3. Gateway service is active after restart
4. All 7 agents still loading (check gateway startup logs for agent count)
5. content-editor skill shows as "ready" in skills list
</verification>

<success_criteria>
- content-editor SKILL.md created with YAML frontmatter, scoring rubric (SEO/readability/accuracy 1-10), reviewer notes format, approval/revision routing, article claiming, and activity logging
- REVIEW_SESSION.md deployed to Sage workspace with review session workflow using /workspace/ sandbox paths
- Gateway restarts cleanly with new skill detected
- All 7 agents (main, landos, rangeos, ops, quill, sage, ezra) remain operational
</success_criteria>

<output>
After completion, create `.planning/phases/15-review-pipeline/15-01-SUMMARY.md`
</output>
